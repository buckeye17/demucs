{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QLNJja0ADoWq"
      },
      "source": [
        "# Inputs\n",
        "Adjust the parameters below.  If the whole audio file is to be processed as a single set, you can make `SET_LS = []`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "383Ph_YWvVzT"
      },
      "outputs": [],
      "source": [
        "SET_LS = [\n",
        "    {\n",
        "      \"filename\": \"set_#1\",\n",
        "      \"title\": \"Set #1\",\n",
        "      \"start\": \"3:49\",\n",
        "      \"end\": \"12:45\"\n",
        "    },\n",
        "    {\n",
        "      \"filename\": \"set_#2\",\n",
        "      \"title\": \"Set #2\",\n",
        "      \"start\": \"14:02\",\n",
        "      \"end\": \"19:13\"\n",
        "    },\n",
        "    {\n",
        "      \"filename\": \"set_#3\",\n",
        "      \"title\": \"Set #3\",\n",
        "      \"start\": \"19:45\",\n",
        "      \"end\": \"23:20\"\n",
        "    }\n",
        "]\n",
        "DESIRED_HZ = 10 # how dense volume data will appear in graphs\n",
        "FPS = 10 # frame rate for output video\n",
        "TIME_WINDOW_SEC = 20 # seconds into future shown in graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXKFvf4LEvRo"
      },
      "source": [
        "# File Upload\n",
        "Use the button below to select the audio file that is to be processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1uCVtWo0qdrb",
        "outputId": "718b168b-1e88-44b8-f42c-0738aa7cd155"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6cf357b6-3a6f-4e50-8224-51cfb6711b53\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6cf357b6-3a6f-4e50-8224-51cfb6711b53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 2.9.23 Practice_01.mp3 to 2.9.23 Practice_01.mp3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "data_to_load_dict = files.upload()\n",
        "\n",
        "# only process the first file in the list\n",
        "fn = list(data_to_load_dict.keys())[0]\n",
        "file_bytes = data_to_load_dict[fn]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxG6PqSkFD27"
      },
      "source": [
        "# Process Audio, Generate Video(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPYDnptMoFcX",
        "outputId": "0436fcff-a922-4f24-e44e-09029f5ad824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, kaleido\n",
            "Successfully installed kaleido-0.2.1 pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install kaleido pydub\n",
        "\n",
        "# import native packages\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from shutil import rmtree\n",
        "import subprocess\n",
        "\n",
        "# import third party packages\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pydub\n",
        "import torch as th\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBV58FgUoU8O",
        "outputId": "41b5cd75-35aa-4424-8070-d4d7d2c8c173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting demucs\n",
            "  Cloning https://github.com/facebookresearch/demucs to /tmp/pip-install-s28emfbs/demucs_5de5596d4e7444c5832f5e3f839ffe26\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs /tmp/pip-install-s28emfbs/demucs_5de5596d4e7444c5832f5e3f839ffe26\n",
            "  Resolved https://github.com/facebookresearch/demucs to commit 3b8430c12242bbbba48769eed6da5190c6ff3c2d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dora-search\n",
            "  Downloading dora_search-0.1.11.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diffq>=0.2.1\n",
            "  Downloading diffq-0.2.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.3/446.3 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting julius>=0.2.3\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2\n",
            "  Downloading lameenc-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.6/189.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openunmix\n",
            "  Downloading openunmix-1.2.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from demucs) (6.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from demucs) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.8/dist-packages (from demucs) (0.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from demucs) (4.64.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from diffq>=0.2.1->demucs) (0.29.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffq>=0.2.1->demucs) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.1->demucs) (4.4.0)\n",
            "Collecting treetable\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting submitit\n",
            "  Downloading submitit-1.4.5-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from retrying->dora-search->demucs) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from submitit->dora-search->demucs) (2.2.1)\n",
            "Building wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.0.0-py3-none-any.whl size=76630 sha256=d90579b2211009624f2858894e4e2b93d469cbc7a67d51925188c0e9c022cac1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k150n6kv/wheels/aa/e1/ef/dd00c4df7b3e6dc06c9afa5048c7ab3aaf043cb63b97e78ccf\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21895 sha256=8a33baebe8b3633c535584e744cc66d7171462c02ea6f5450cc191557490d989\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/89/4f/88596b58a42ee452100fe1cd6ac31265bb192e597cf85908da\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.11-py3-none-any.whl size=75008 sha256=38831fdb88236866adc254b78ef0c4bf2742f25f9383067343c9ccb33ad4dbc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/42/69/2259709315acf43bd7b9876fb35454db01f770b63519966ac9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=45361a3c110524fb9244f38c7b6e4a7e213356d029bb7670f4766eea43f832a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7347 sha256=48f38a4b0b5d3881ea5b0b41ac0b73a60571e14dc487438bb0a4a762c24b34be\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/ac/31/490968d6fc824620f9f04f03a2f90149bbbbcdb6c6e614909c\n",
            "Successfully built demucs julius dora-search antlr4-python3-runtime treetable\n",
            "Installing collected packages: lameenc, antlr4-python3-runtime, treetable, submitit, retrying, omegaconf, einops, julius, dora-search, diffq, openunmix, demucs\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 demucs-4.0.0 diffq-0.2.3 dora-search-0.1.11 einops-0.6.0 julius-0.2.7 lameenc-1.4.2 omegaconf-2.3.0 openunmix-1.2.1 retrying-1.3.4 submitit-1.4.5 treetable-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs\n",
        "\n",
        "# import local demucs modules\n",
        "from demucs.apply import apply_model, BagOfModels\n",
        "from demucs.audio import AudioFile, convert_audio, save_audio\n",
        "from demucs.pretrained import get_model_from_args, add_model_flags, ModelLoadingError\n",
        "from demucs.separate import load_track\n",
        "from dora.log import fatal\n",
        "\n",
        "def sec_to_hms(seconds):\n",
        "    seconds = seconds % (24 * 3600)\n",
        "    hour = seconds // 3600\n",
        "    seconds %= 3600\n",
        "    minutes = seconds // 60\n",
        "    seconds %= 60\n",
        "     \n",
        "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GLENLeOX2RJL"
      },
      "outputs": [],
      "source": [
        "# Setup results directory\n",
        "results_path = Path('results')\n",
        "if results_path.exists():\n",
        "    rmtree(results_path)\n",
        "results_path.mkdir()\n",
        "\n",
        "results_images_path = Path('results/images')\n",
        "results_images_path.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "8b7ebb3e31c945fcbf87ba81de59e040",
            "d43f4c92cdfa4ad7aad4f2785849ab98",
            "b99e80214efd4532843fd4d1658f3f7b",
            "24b43c9c810f49a89568a0228bfb854f",
            "12ad7eb4cabe4511a733b337e823f757",
            "c8fbe5ee326f410d83e0be3870c31cd2",
            "748e2986c8914d37a7fd977194762a54",
            "2e017a403efb42d0ada622428d50997e",
            "ba0594462acb4addbad8234513c497de",
            "24ad7f45b26246b6a3747e3c9214ce4a",
            "2561f0013c444dac8c28fd64f9e04ff6"
          ]
        },
        "id": "cYAABtS5v4Ea",
        "outputId": "bf1b1ba3-ee9b-4d5d-9e22-ef797345a6b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/5c90dfd2-34c22ccb.th\" to /root/.cache/torch/hub/checkpoints/5c90dfd2-34c22ccb.th\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b7ebb3e31c945fcbf87ba81de59e040",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/52.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:29<00:00, 18.24seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:23<00:00, 22.86seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.01seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.24seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:23<00:00, 22.49seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.36seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.30seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.31seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.34seconds/s]\n",
            "100%|████████████████████████████████████████████████| 538.1999999999999/538.1999999999999 [00:24<00:00, 22.35seconds/s]\n",
            "100%|██████████| 5361/5361 [40:21<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set #1 processing time summary:\n",
            "Audio processing took 0:11:35 (hours:minutes:seconds)\n",
            "Video generation took 0:43:33 (hours:minutes:seconds)\n",
            "The entire script took 0:55:09 (hours:minutes:seconds)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.06seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.02seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 21.94seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.04seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.39seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.35seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.04seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.22seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.20seconds/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 315.9/315.9 [00:14<00:00, 22.04seconds/s]\n",
            "100%|██████████| 3111/3111 [23:22<00:00,  2.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set #2 processing time summary:\n",
            "Audio processing took 0:50:10 (hours:minutes:seconds)\n",
            "Video generation took 0:25:12 (hours:minutes:seconds)\n",
            "The entire script took 1:15:23 (hours:minutes:seconds)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.44seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.10seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.08seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 21.65seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.30seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 21.90seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.56seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.27seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.37seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 216.45/216.45 [00:09<00:00, 22.20seconds/s]\n",
            "100%|██████████| 2151/2151 [16:13<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set #3 processing time summary:\n",
            "Audio processing took 0:29:53 (hours:minutes:seconds)\n",
            "Video generation took 0:17:29 (hours:minutes:seconds)\n",
            "The entire script took 0:47:23 (hours:minutes:seconds)\n"
          ]
        }
      ],
      "source": [
        "tic = time.perf_counter()\n",
        "\n",
        "# convert set list from MM:SS to seconds\n",
        "def mm_ss_to_sec(mm_ss: str):\n",
        "    mm_ss_ls = mm_ss.split(\":\")\n",
        "    mm_ss_ls = [int(x) for x in mm_ss_ls]\n",
        "    return mm_ss_ls[0]*60 + mm_ss_ls[1]\n",
        "\n",
        "if SET_LS:\n",
        "    for i, set_dict in enumerate(SET_LS):\n",
        "        for key in [\"start\", \"end\"]:\n",
        "            SET_LS[i][key] = mm_ss_to_sec(set_dict[key])\n",
        "else:\n",
        "    SET_LS = [{\n",
        "        \"filename\": \"set_#1\",\n",
        "        \"title\": \"Set #1\",\n",
        "        \"start\": None,\n",
        "        \"end\": None\n",
        "      }]\n",
        "\n",
        "# setup the demucs AI model for processing\n",
        "'''\n",
        "demucs algorithm names are as follows:\n",
        "htdemucs: first version of Hybrid Transformer Demucs. Trained on MusDB + 800 songs. Default model.\n",
        "htdemucs_ft: fine-tuned version of htdemucs, separation will take 4 times more time but might be a bit better. Same training set as htdemucs.\n",
        "htdemucs_6s: 6 sources version of htdemucs, with piano and guitar being added as sources. Note that the piano source is not working great at the moment.\n",
        "hdemucs_mmi: Hybrid Demucs v3, retrained on MusDB + 800 songs.\n",
        "mdx: trained only on MusDB HQ, winning model on track A at the MDX challenge.\n",
        "mdx_extra: trained with extra training data (including MusDB test set), ranked 2nd on the track B of the MDX challenge.\n",
        "mdx_q, mdx_extra_q: quantized version of the previous models. Smaller download and storage but quality can be slightly worse.\n",
        "SIG: where SIG is a single model from the model zoo.\n",
        "'''\n",
        "class Args:\n",
        "    name = \"htdemucs_6s\"\n",
        "    repo = None\n",
        "args = Args()\n",
        "\n",
        "try:\n",
        "    model = get_model_from_args(args)\n",
        "except ModelLoadingError as error:\n",
        "    fatal(error.args[0])\n",
        "\n",
        "# Set split size of each chunk. This can help save memory of graphic card. \n",
        "n_segment = None\n",
        "\n",
        "if isinstance(model, BagOfModels):\n",
        "    print(f\"Selected model is a bag of {len(model.models)} models. \"\n",
        "            \"You will see that many progress bars per track.\")\n",
        "    if n_segment is not None:\n",
        "        for sub in model.models:\n",
        "            sub.segment = n_segment\n",
        "else:\n",
        "    if n_segment is not None:\n",
        "        model.segment = n_segment\n",
        "\n",
        "model.cpu()\n",
        "model.eval()\n",
        "\n",
        "default=Path(\"separated\"),\n",
        "\n",
        "# Device to use, default is cuda if available else cpu\n",
        "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Number of random shifts for equivariant stabilization.\"\n",
        "# Increase separation time but improves quality for Demucs. 10 was used in the original paper.\")\n",
        "shifts = 10 # must be integer\n",
        "\n",
        "# Doesn't split audio in chunks. This can use large amounts of memory.\n",
        "split_bool = True\n",
        "\n",
        "# Overlap between the splits\n",
        "overlap = 0.25\n",
        "\n",
        "# Number of jobs. This can increase memory usage but will be much faster when multiple cores are available.\n",
        "n_jobs = 0\n",
        "\n",
        "# process each set\n",
        "# recording = pydub.AudioSegment.from_mp3(INPUT_FN)\n",
        "recording = pydub.AudioSegment.from_mp3(io.BytesIO(file_bytes))\n",
        "for i_set, set_dict in enumerate(SET_LS):\n",
        "\n",
        "    # make an MP3 for each set\n",
        "    set_fn = f\"results/set_#{i_set + 1}.mp3\"\n",
        "\n",
        "    if set_dict[\"start\"]:\n",
        "        set_clip = recording[set_dict[\"start\"]*1000:set_dict[\"end\"]*1000]\n",
        "    else:\n",
        "        set_clip = recording\n",
        "    set_clip.export(set_fn, format=\"mp3\")\n",
        "    wav = load_track(set_fn, model.audio_channels, model.samplerate)\n",
        "\n",
        "    ref = wav.mean(0)\n",
        "    wav = (wav - ref.mean()) / ref.std()\n",
        "    sources = apply_model(model, wav[None], device=device, shifts=shifts,\n",
        "                            split=split_bool, overlap=overlap, progress=True,\n",
        "                            num_workers=n_jobs)[0]\n",
        "    sources = sources * ref.std() + ref.mean()\n",
        "\n",
        "    ext = \"mp3\" # valid values: mp3, wav\n",
        "\n",
        "    # Bitrate of converted mp3, must be an integer, default 320\n",
        "    bitrate = 320\n",
        "\n",
        "    # Strategy for avoiding clipping: rescaling entire signal if necessary  (rescale) or hard clipping (clamp).\")\n",
        "    clip_mode = \"rescale\" # valid values: rescale, clamp\n",
        "\n",
        "    # Save wav output as float32 (2x bigger)\n",
        "    out_float32_bool = False\n",
        "\n",
        "    # Save wav output as 24 bits or 16 bits wav\n",
        "    out_int24_bool = False\n",
        "\n",
        "    kwargs = {\n",
        "        'samplerate': model.samplerate,\n",
        "        'bitrate': bitrate,\n",
        "        'clip': clip_mode,\n",
        "        'as_float': out_float32_bool,\n",
        "        'bits_per_sample': 24 if out_int24_bool else 16,\n",
        "    }\n",
        "\n",
        "    frame_img_ls = []\n",
        "    df = pd.DataFrame()\n",
        "    for source, name in zip(sources, model.sources):\n",
        "        track_fn = f\"results/{name}.mp3\"\n",
        "        save_audio(source, track_fn, **kwargs)\n",
        "        \n",
        "        # read the track as a numpy array\n",
        "        # the following code was adapted from: https://stackoverflow.com/questions/53633177/how-to-read-a-mp3-audio-file-into-a-numpy-array-save-a-numpy-array-to-mp3\n",
        "        a = pydub.AudioSegment.from_mp3(track_fn)\n",
        "        os.remove(track_fn)\n",
        "        y = np.array(a.get_array_of_samples())\n",
        "        if a.channels == 2:\n",
        "            y = y.reshape((-1, 2))\n",
        "            y = np.average(y, axis=1)\n",
        "        fr = a.frame_rate\n",
        "        audio_arr = np.float32(y) / 2**15\n",
        "\n",
        "        # resample file so data is only shown for every tenth of second instead of 44.1kHz\n",
        "        sample_block_len = int(np.floor(fr/DESIRED_HZ))\n",
        "        \n",
        "        # need to pad zeros on end of audio so it can be reshaped into full blocks for resampling\n",
        "        n_blocks = int(np.ceil(len(audio_arr)/sample_block_len))\n",
        "        n_pad = n_blocks*sample_block_len - len(audio_arr)\n",
        "        audio_arr = np.concatenate((audio_arr, np.zeros((n_pad))))\n",
        "        audio_arr = audio_arr.reshape(-1, sample_block_len).max(axis=1)\n",
        "\n",
        "        # make sure signal doesn't go negative\n",
        "        if audio_arr.min() < 0:\n",
        "            audio_arr -= audio_arr.min()\n",
        "\n",
        "        df[name] = audio_arr\n",
        "\n",
        "    volume_max = df.max().max()\n",
        "    df[\"time_ms\"] = np.arange(0, len(df)/DESIRED_HZ*1000, 1000/DESIRED_HZ) # plotly requires time axis in milliseconds\n",
        "    df[\"time_ms\"] = pd.to_datetime(df[\"time_ms\"], unit='ms')\n",
        "\n",
        "    toc = time.perf_counter()\n",
        "    audio_proc_time = toc - tic\n",
        "    tic = time.perf_counter()\n",
        "\n",
        "    # make video frames\n",
        "    n_frames = int(len(df)*FPS/DESIRED_HZ)\n",
        "    duration_sec = n_frames/FPS\n",
        "    for i_frame in tqdm(range(n_frames)):\n",
        "\n",
        "        audio_start_sec = i_frame/FPS\n",
        "        audio_end_sec = audio_start_sec + TIME_WINDOW_SEC #min(audio_start_sec + TIME_WINDOW_SEC, duration_sec)\n",
        "        time_ms_min = pd.to_datetime(audio_start_sec*1000, unit='ms')\n",
        "        time_ms_max = pd.to_datetime(audio_end_sec*1000, unit='ms')\n",
        "\n",
        "        frame_df = df.loc[(df.time_ms >= time_ms_min) & (df.time_ms <= time_ms_max), :]\n",
        "        # frame_df.to_csv(\"results/a.csv\")\n",
        "        \n",
        "        fig = make_subplots(rows=1, cols=6, subplot_titles=model.sources)\n",
        "        for i_track, name in enumerate(model.sources):\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    y = frame_df.time_ms,\n",
        "                    x = frame_df[name],\n",
        "                    fill = 'tozerox'\n",
        "                ),\n",
        "                row = 1,\n",
        "                col = i_track + 1\n",
        "            )\n",
        "\n",
        "        # set subtitle font size, move them down onto plots\n",
        "        fig.update_annotations(font_size=40, yshift=-150)\n",
        "        \n",
        "        xaxis_format_dict = dict(\n",
        "            showticklabels=False,\n",
        "            linewidth=5,\n",
        "            showline=True,\n",
        "            # linecolor=\"#CCCCCC\",\n",
        "            range=[0, volume_max]\n",
        "        )\n",
        "\n",
        "        yaxis_format_dict = dict(\n",
        "            dtick=TIME_WINDOW_SEC*1000/4, # pd.to_datetime(TIME_WINDOW_SEC*1000/4, unit='ms'),\n",
        "            type=\"date\",\n",
        "            tickfont=dict(size=15),\n",
        "            tickformat=\"%M:%S\", # \"%M:%S.%L ms\"\n",
        "            range=[time_ms_min, time_ms_max],\n",
        "            showgrid=True,\n",
        "            gridwidth=2,\n",
        "            # gridcolor=\"#CCCCCC\"\n",
        "        )\n",
        "\n",
        "        title = SET_LS[i_set][\"title\"][:1].upper() + SET_LS[i_set][\"title\"][1:]\n",
        "        fig.update_layout(\n",
        "            title={\n",
        "                \"text\": title,\n",
        "                \"font\": {\"color\": \"#666666\"},\n",
        "                \"xanchor\": \"center\",\n",
        "                # \"yanchor\": \"top\",\n",
        "                \"x\": 0.5,\n",
        "                # \"y\": 1,\n",
        "                # \"pad\": {\"t\": 50}\n",
        "            },\n",
        "            xaxis_title=\"\",\n",
        "            yaxis_title=\"Time\",\n",
        "            # plot_bgcolor=\"white\",\n",
        "            font={\"size\": 25},\n",
        "            template=\"plotly_dark\",\n",
        "            showlegend=False,\n",
        "            autosize=False,\n",
        "            width=1920,\n",
        "            height=1080,\n",
        "            xaxis=xaxis_format_dict,\n",
        "            xaxis2=xaxis_format_dict,\n",
        "            xaxis3=xaxis_format_dict,\n",
        "            xaxis4=xaxis_format_dict,\n",
        "            xaxis5=xaxis_format_dict,\n",
        "            xaxis6=xaxis_format_dict,\n",
        "            yaxis1=yaxis_format_dict,\n",
        "            yaxis2=yaxis_format_dict,\n",
        "            yaxis3=yaxis_format_dict,\n",
        "            yaxis4=yaxis_format_dict,\n",
        "            yaxis5=yaxis_format_dict,\n",
        "            yaxis6=yaxis_format_dict,\n",
        "        )\n",
        "\n",
        "        # fig.show()\n",
        "        frame_img_ls.append(f\"results/images/{str(i_frame).zfill(6)}.jpg\")\n",
        "        fig.write_image(f\"results/images/{str(i_frame).zfill(6)}.jpg\")\n",
        "\n",
        "    # generate video file from image files created above\n",
        "    frame_size = (1920, 1080)\n",
        "    set_video_temp_path = \"results/temp.mp4\"\n",
        "    out = cv.VideoWriter(set_video_temp_path, cv.VideoWriter_fourcc(*'mp4v'), FPS, frame_size)\n",
        "\n",
        "    for img_fn in frame_img_ls:\n",
        "        img = cv.imread(img_fn)\n",
        "        out.write(img)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    # attach audio to video file created above\n",
        "    cmd = f\"ffmpeg -i {set_video_temp_path} -i {set_fn} -map 0:0 -map 1:0 -c:v copy -c:a copy {SET_LS[i_set]['filename']}.mp4\"\n",
        "    cmd = cmd.split(\" \")\n",
        "\n",
        "    # returns output as byte string\n",
        "    returned_output = subprocess.check_output(cmd)\n",
        "\n",
        "    # use decode() to convert byte string to human readable string\n",
        "    output_str = returned_output.decode(\"utf-8\")\n",
        "\n",
        "    # make subprocess outputs visible to terminal\n",
        "    # print(output_str)\n",
        "\n",
        "    # delete temporary files\n",
        "    os.remove(set_video_temp_path)\n",
        "    os.remove(set_fn)\n",
        "\n",
        "    toc = time.perf_counter()\n",
        "    video_proc_time = toc - tic\n",
        "    print(f\"Set #{i_set + 1} processing time summary:\")\n",
        "    print(f\"Audio processing took {sec_to_hms(audio_proc_time)} (hours:minutes:seconds)\")\n",
        "    print(f\"Video generation took {sec_to_hms(video_proc_time)} (hours:minutes:seconds)\")\n",
        "    print(f\"The entire script took {sec_to_hms(audio_proc_time + video_proc_time)} (hours:minutes:seconds)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12ad7eb4cabe4511a733b337e823f757": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ad7f45b26246b6a3747e3c9214ce4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b43c9c810f49a89568a0228bfb854f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ad7f45b26246b6a3747e3c9214ce4a",
            "placeholder": "​",
            "style": "IPY_MODEL_2561f0013c444dac8c28fd64f9e04ff6",
            "value": " 52.4M/52.4M [00:00&lt;00:00, 56.9MB/s]"
          }
        },
        "2561f0013c444dac8c28fd64f9e04ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e017a403efb42d0ada622428d50997e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748e2986c8914d37a7fd977194762a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b7ebb3e31c945fcbf87ba81de59e040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d43f4c92cdfa4ad7aad4f2785849ab98",
              "IPY_MODEL_b99e80214efd4532843fd4d1658f3f7b",
              "IPY_MODEL_24b43c9c810f49a89568a0228bfb854f"
            ],
            "layout": "IPY_MODEL_12ad7eb4cabe4511a733b337e823f757"
          }
        },
        "b99e80214efd4532843fd4d1658f3f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e017a403efb42d0ada622428d50997e",
            "max": 54996327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0594462acb4addbad8234513c497de",
            "value": 54996327
          }
        },
        "ba0594462acb4addbad8234513c497de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8fbe5ee326f410d83e0be3870c31cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43f4c92cdfa4ad7aad4f2785849ab98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fbe5ee326f410d83e0be3870c31cd2",
            "placeholder": "​",
            "style": "IPY_MODEL_748e2986c8914d37a7fd977194762a54",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
